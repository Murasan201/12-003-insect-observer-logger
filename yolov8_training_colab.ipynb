{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": "# üêõ Google Colab‰∏ä„Åß„ÅÆYOLOv8ÊòÜËô´Ê§úÂá∫„Éà„É¨„Éº„Éã„É≥„Ç∞\n\n**„Éó„É≠„Ç∏„Çß„ÇØ„Éà**: ÊòÜËô´Ê§úÂá∫„Éà„É¨„Éº„Éã„É≥„Ç∞„Éó„É≠„Ç∏„Çß„ÇØ„Éà  \n**ÁõÆÁöÑ**: Roboflow„Éá„Éº„Çø„Çª„ÉÉ„Éà„Çí‰ΩøÁî®„Åó„Å¶„Ç´„Éñ„Éà„É†„Ç∑Ê§úÂá∫„ÅÆ„Åü„ÇÅ„ÅÆ„Ç´„Çπ„Çø„É†YOLOv8„É¢„Éá„É´„ÇíË®ìÁ∑¥  \n**Áí∞Â¢É**: GPUÂä†ÈÄü‰ªò„ÅçGoogle Colaboratory  \n\n---\n\n## üìã Ê¶ÇË¶Å\n\n„Åì„ÅÆ„Éé„Éº„Éà„Éñ„ÉÉ„ÇØ„ÅØYOLOv8ÊòÜËô´Ê§úÂá∫„É¢„Éá„É´„ÅÆ„Åü„ÇÅ„ÅÆ„Ç§„É≥„Çø„É©„ÇØ„ÉÜ„Ç£„Éñ„Éà„É¨„Éº„Éã„É≥„Ç∞„Éë„Ç§„Éó„É©„Ç§„É≥„ÇíÊèê‰æõ„Åó„Åæ„Åô„ÄÇÂê´„Åæ„Çå„ÇãÊ©üËÉΩ:\n\n- ‚úÖ Ëá™ÂãïÂåñ„Åï„Çå„ÅüÁí∞Â¢É„Çª„ÉÉ„Éà„Ç¢„ÉÉ„Éó\n- ‚úÖ GPUË®≠ÂÆö„Å®Ê§úË®º\n- ‚úÖ „Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆÊ∫ñÂÇô„Å®Ê§úË®º\n- ‚úÖ „Ç§„É≥„Çø„É©„ÇØ„ÉÜ„Ç£„Éñ„Å™„É¢„Éá„É´„Éà„É¨„Éº„Éã„É≥„Ç∞\n- ‚úÖ „É™„Ç¢„É´„Çø„Ç§„É†ÈÄ≤ÊçóÁõ£Ë¶ñ\n- ‚úÖ „É¢„Éá„É´Ë©ï‰æ°„Å®„Ç®„ÇØ„Çπ„Éù„Éº„Éà\n- ‚úÖ ÁµêÊûú„ÅÆÂèØË¶ñÂåñ\n\n---\n\n## ‚ö° „ÇØ„Ç§„ÉÉ„ÇØ„Çπ„Çø„Éº„Éà\n\n1. **GPU„ÇíÊúâÂäπÂåñ**: „É©„É≥„Çø„Ç§„É† ‚Üí „É©„É≥„Çø„Ç§„É†„Çø„Ç§„Éó„ÅÆÂ§âÊõ¥ ‚Üí GPU„ÇíÈÅ∏Êäû\n2. **„Åô„Åπ„Å¶„ÅÆ„Çª„É´„ÇíÂÆüË°å**: „É©„É≥„Çø„Ç§„É† ‚Üí „Åô„Åπ„Å¶„ÅÆ„Çª„É´„ÇíÂÆüË°å\n3. **„Éá„Éº„Çø„Çª„ÉÉ„Éà„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ**: „Éó„É≠„É≥„Éó„Éà„Å´Âæì„Å£„Å¶„Éá„Éº„Çø„Çª„ÉÉ„Éà„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ\n4. **„Éà„É¨„Éº„Éã„É≥„Ç∞„ÇíÁõ£Ë¶ñ**: „É™„Ç¢„É´„Çø„Ç§„É†„Éà„É¨„Éº„Éã„É≥„Ç∞ÈÄ≤Êçó„ÇíÁõ£Ë¶ñ\n5. **ÁµêÊûú„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ**: Ë®ìÁ∑¥Ê∏à„Åø„É¢„Éá„É´„ÇíGoogle Drive„Å´‰øùÂ≠ò\n\n---",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-header"
   },
   "source": "## üõ†Ô∏è „Çπ„ÉÜ„ÉÉ„Éó1: Áí∞Â¢É„Çª„ÉÉ„Éà„Ç¢„ÉÉ„Éó„Å®„É©„Ç§„Éñ„É©„É™„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "install-libraries"
   },
   "outputs": [],
   "source": "# ÂøÖË¶Å„Å™„É©„Ç§„Éñ„É©„É™„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´\nprint(\"üîß ÂøÖË¶Å„Å™„É©„Ç§„Éñ„É©„É™„Çí„Ç§„É≥„Çπ„Éà„Éº„É´‰∏≠...\")\n\n!pip install ultralytics roboflow supervision\n!pip install --upgrade torch torchvision\n\nprint(\"‚úÖ „Ç§„É≥„Çπ„Éà„Éº„É´„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„ÅüÔºÅ\")"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "import-libraries"
   },
   "outputs": [],
   "source": "# ÂøÖË¶Å„Å™„É©„Ç§„Éñ„É©„É™„ÅÆ„Ç§„É≥„Éù„Éº„Éà\nimport os\nimport sys\nimport time\nimport shutil\nimport zipfile\nfrom pathlib import Path\nfrom datetime import datetime\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Ê∑±Â±§Â≠¶Áøí„É©„Ç§„Éñ„É©„É™\nimport torch\nimport torchvision\nfrom ultralytics import YOLO\n\n# „Éá„Éº„ÇøÊìç‰Ωú„Å®ÂèØË¶ñÂåñ\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import Image, display, HTML, clear_output\nimport cv2\n\n# Google ColabÂ∞ÇÁî®\nfrom google.colab import files, drive\nimport yaml\n\nprint(\"üìö „É©„Ç§„Éñ„É©„É™„ÅÆ„Ç§„É≥„Éù„Éº„Éà„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„ÅüÔºÅ\")\nprint(f\"üêç Python„Éê„Éº„Ç∏„Éß„É≥: {sys.version}\")\nprint(f\"üî• PyTorch„Éê„Éº„Ç∏„Éß„É≥: {torch.__version__}\")\nprint(f\"üëÅÔ∏è OpenCV„Éê„Éº„Ç∏„Éß„É≥: {cv2.__version__}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpu-header"
   },
   "source": "## üöÄ „Çπ„ÉÜ„ÉÉ„Éó2: GPUË®≠ÂÆö„Å®„Ç∑„Çπ„ÉÜ„É†Ê§úË®º",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "check-gpu"
   },
   "outputs": [],
   "source": "# GPUÂèØÁî®ÊÄß„Å®Ë®≠ÂÆö„ÅÆÁ¢∫Ë™ç\ndef check_gpu_setup():\n    \"\"\"GPUË®≠ÂÆö„Çí„ÉÅ„Çß„ÉÉ„ÇØ„Åó„ÄÅÂà©Áî®ÂèØËÉΩ„Å™Â†¥Âêà„ÅØ„Éá„Éê„Ç§„Çπ„ÇíË®≠ÂÆö„Åô„Çã\"\"\"\n    print(\"üîç GPUË®≠ÂÆö„ÇíÁ¢∫Ë™ç‰∏≠...\")\n    print(\"=\"*50)\n    \n    # CUDAÂèØÁî®ÊÄß„ÅÆÁ¢∫Ë™ç\n    cuda_available = torch.cuda.is_available()\n    print(f\"CUDAÂà©Áî®ÂèØËÉΩ: {cuda_available}\")\n    \n    if cuda_available:\n        device_count = torch.cuda.device_count()\n        print(f\"GPUÊï∞: {device_count}\")\n        \n        for i in range(device_count):\n            gpu_name = torch.cuda.get_device_name(i)\n            gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1e9\n            print(f\"GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)\")\n        \n        # „Éá„Éê„Ç§„Çπ„ÅÆË®≠ÂÆö\n        device = torch.device('cuda:0')\n        print(f\"\\n‚úÖ ‰ΩøÁî®„Éá„Éê„Ç§„Çπ: {device}\")\n        \n        # Á∞°Âçò„Å™ÊºîÁÆó„ÅßGPU„Çí„ÉÜ„Çπ„Éà\n        test_tensor = torch.rand(1000, 1000).to(device)\n        result = torch.mm(test_tensor, test_tensor.t())\n        print(\"‚úÖ GPU„ÉÜ„Çπ„ÉàÊìç‰Ωú„ÅåÊàêÂäü„Åó„Åæ„Åó„ÅüÔºÅ\")\n        \n    else:\n        print(\"‚ö†Ô∏è GPU„ÅåÂà©Áî®„Åß„Åç„Åæ„Åõ„Çì„ÄÇ„Éà„É¨„Éº„Éã„É≥„Ç∞„ÅØCPU„Çí‰ΩøÁî®„Åó„Åæ„ÅôÔºà‰ΩéÈÄüÔºâ„ÄÇ\")\n        device = torch.device('cpu')\n    \n    print(\"=\"*50)\n    return device\n\n# GPUÁ¢∫Ë™ç„ÅÆÂÆüË°å\ntraining_device = check_gpu_setup()"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "system-info"
   },
   "outputs": [],
   "source": "# „Ç∑„Çπ„ÉÜ„É†ÊÉÖÂ†±„ÅÆË°®Á§∫\ndef display_system_info():\n    \"\"\"„Ç∑„Çπ„ÉÜ„É†ÊÉÖÂ†±„ÇíË°®Á§∫„Åô„Çã\"\"\"\n    print(\"üíª „Ç∑„Çπ„ÉÜ„É†ÊÉÖÂ†±\")\n    print(\"=\"*40)\n    \n    # CPUÊÉÖÂ†±\n    print(f\"CPU„Ç≥„Ç¢Êï∞: {os.cpu_count()}\")\n    \n    # „É°„É¢„É™ÊÉÖÂ†±ÔºàÊ¶ÇÁÆóÔºâ\n    import psutil\n    memory = psutil.virtual_memory()\n    print(f\"RAM: {memory.total / 1e9:.1f} GB ÔºàÂà©Áî®ÂèØËÉΩ: {memory.available / 1e9:.1f} GBÔºâ\")\n    \n    # „Éá„Ç£„Çπ„ÇØÂÆπÈáè\n    disk = psutil.disk_usage('/')\n    print(f\"„Éá„Ç£„Çπ„ÇØ: {disk.total / 1e9:.1f} GB ÔºàÁ©∫„Åç: {disk.free / 1e9:.1f} GBÔºâ\")\n    \n    print(\"\\nüîß „ÇΩ„Éï„Éà„Ç¶„Çß„Ç¢„Éê„Éº„Ç∏„Éß„É≥\")\n    print(\"=\"*40)\n    print(f\"Python: {sys.version.split()[0]}\")\n    print(f\"PyTorch: {torch.__version__}\")\n    print(f\"Torchvision: {torchvision.__version__}\")\n    print(f\"OpenCV: {cv2.__version__}\")\n    print(f\"NumPy: {np.__version__}\")\n    \ndisplay_system_info()"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drive-header"
   },
   "source": "## üìÅ „Çπ„ÉÜ„ÉÉ„Éó3: Google DriveÈÄ£Êê∫„Å®„Éá„Éº„Çø„Çª„ÉÉ„Éà„Çª„ÉÉ„Éà„Ç¢„ÉÉ„Éó",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mount-drive"
   },
   "outputs": [],
   "source": "# Google Drive„Çí„Éû„Ç¶„É≥„Éà\nprint(\"üìÅ Google Drive„Çí„Éû„Ç¶„É≥„Éà‰∏≠...\")\ndrive.mount('/content/drive')\n\n# Google DriveÂÜÖ„Å´„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Éá„Ç£„É¨„ÇØ„Éà„É™„Çí‰ΩúÊàê\nproject_dir = Path('/content/drive/MyDrive/insect_detection_training')\nproject_dir.mkdir(exist_ok=True)\n\n# „Çµ„Éñ„Éá„Ç£„É¨„ÇØ„Éà„É™„Çí‰ΩúÊàê\n(project_dir / 'datasets').mkdir(exist_ok=True)\n(project_dir / 'models').mkdir(exist_ok=True)\n(project_dir / 'results').mkdir(exist_ok=True)\n(project_dir / 'logs').mkdir(exist_ok=True)\n\nprint(f\"‚úÖ „Éó„É≠„Ç∏„Çß„ÇØ„Éà„Éá„Ç£„É¨„ÇØ„Éà„É™„Çí‰ΩúÊàê„Åó„Åæ„Åó„Åü: {project_dir}\")\nprint(f\"üìÇ ‰ΩúÊ•≠„Éá„Ç£„É¨„ÇØ„Éà„É™: {os.getcwd()}\")\n\n# ‰ΩúÊ•≠„Éá„Ç£„É¨„ÇØ„Éà„É™„ÇíË®≠ÂÆö\nos.chdir('/content')\nprint(f\"üìÅ ‰ΩúÊ•≠„Éá„Ç£„É¨„ÇØ„Éà„É™„ÇíÂ§âÊõ¥„Åó„Åæ„Åó„Åü: {os.getcwd()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset-header"
   },
   "source": "## üìä „Çπ„ÉÜ„ÉÉ„Éó4: „Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆÊ∫ñÂÇô„Å®„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ\n\n### „Ç™„Éó„Ç∑„Éß„É≥A: „É≠„Éº„Ç´„É´„Ç≥„É≥„Éî„É•„Éº„Çø„Éº„Åã„Çâ„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "upload-dataset"
   },
   "outputs": [],
   "source": "# „Ç™„Éó„Ç∑„Éß„É≥A: „É≠„Éº„Ç´„É´„Ç≥„É≥„Éî„É•„Éº„Çø„Éº„Åã„Çâ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ\ndef upload_dataset_local():\n    \"\"\"„É≠„Éº„Ç´„É´„Ç≥„É≥„Éî„É•„Éº„Çø„Éº„Åã„Çâ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åô„Çã\"\"\"\n    print(\"üì§ „Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆZIP„Éï„Ç°„Ç§„É´„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åó„Å¶„Åè„Å†„Åï„ÅÑ\")\n    print(\"ZIPÂÜÖ„ÅÆÊúüÂæÖ„Åï„Çå„ÇãÊßãÈÄ†:\")\n    print(\"\"\"\n    dataset.zip\n    ‚îú‚îÄ‚îÄ train/\n    ‚îÇ   ‚îú‚îÄ‚îÄ images/\n    ‚îÇ   ‚îî‚îÄ‚îÄ labels/\n    ‚îú‚îÄ‚îÄ valid/\n    ‚îÇ   ‚îú‚îÄ‚îÄ images/\n    ‚îÇ   ‚îî‚îÄ‚îÄ labels/\n    ‚îú‚îÄ‚îÄ test/\n    ‚îÇ   ‚îú‚îÄ‚îÄ images/\n    ‚îÇ   ‚îî‚îÄ‚îÄ labels/\n    ‚îî‚îÄ‚îÄ data.yaml\n    \"\"\")\n    \n    uploaded = files.upload()\n    \n    # „Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åï„Çå„Åü„Éï„Ç°„Ç§„É´„ÇíÂ±ïÈñã\n    for filename in uploaded.keys():\n        if filename.endswith('.zip'):\n            print(f\"üì¶ {filename}„ÇíÂ±ïÈñã‰∏≠...\")\n            with zipfile.ZipFile(filename, 'r') as zip_ref:\n                zip_ref.extractall('datasets')\n            print(\"‚úÖ „Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆÂ±ïÈñã„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„ÅüÔºÅ\")\n            break\n    else:\n        print(\"‚ùå ZIP„Éï„Ç°„Ç§„É´„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÇíÂê´„ÇÄZIP„Éï„Ç°„Ç§„É´„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\")\n        return False\n    \n    return True\n\n# „Éá„Éº„Çø„Çª„ÉÉ„Éà„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ\nupload_success = upload_dataset_local()"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "roboflow-header"
   },
   "source": "### „Ç™„Éó„Ç∑„Éß„É≥B: Roboflow„Åã„Çâ„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÔºàÊé®Â•®Ôºâ",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "roboflow-download"
   },
   "outputs": [],
   "source": "# „Ç™„Éó„Ç∑„Éß„É≥B: Roboflow„Åã„Çâ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ\ndef download_roboflow_dataset():\n    \"\"\"Roboflow„Åã„Çâ„Ç´„Éñ„Éà„É†„Ç∑„Éá„Éº„Çø„Çª„ÉÉ„Éà„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Åô„Çã\"\"\"\n    print(\"ü§ñ Roboflow„Åã„Çâ„Ç´„Éñ„Éà„É†„Ç∑„Éá„Éº„Çø„Çª„ÉÉ„Éà„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ‰∏≠...\")\n    \n    try:\n        from roboflow import Roboflow\n        \n        # Roboflow„ÅÆÂàùÊúüÂåñÔºàAPI„Ç≠„Éº„ÅÆË®≠ÂÆö„ÅåÂøÖË¶Å„Å™Â†¥Âêà„Åå„ÅÇ„Çä„Åæ„ÅôÔºâ\n        # API„Ç≠„Éº„ÅÆÂèñÂæóÂÖà: https://app.roboflow.com/settings/api\n        print(\"üîë Roboflow API„Ç≠„Éº„ÇíÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºà„Çπ„Ç≠„ÉÉ„Éó„Åô„ÇãÂ†¥Âêà„ÅØEnter„ÇíÊäº„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºâ:\")\n        api_key = input(\"API„Ç≠„Éº: \").strip()\n        \n        if api_key:\n            rf = Roboflow(api_key=api_key)\n            project = rf.workspace(\"z-algae-bilby\").project(\"beetle\")\n            dataset = project.version(1).download(\"yolov8\", location=\"datasets\")\n            print(\"‚úÖ Roboflow„Åã„Çâ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Åó„Åæ„Åó„ÅüÔºÅ\")\n            return True\n        else:\n            print(\"‚ö†Ô∏è API„Ç≠„Éº„ÅåÊèê‰æõ„Åï„Çå„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ‰ª•‰∏ã„Åã„ÇâÊâãÂãï„Åß„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Åß„Åç„Åæ„Åô:\")\n            print(\"https://universe.roboflow.com/z-algae-bilby/beetle/dataset/1\")\n            return False\n            \n    except Exception as e:\n        print(f\"‚ùå Roboflow„Åã„Çâ„ÅÆ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Ç®„É©„Éº: {e}\")\n        print(\"üí° ‰ª£ÊõøÊ°à: ÊâãÂãï„Åß„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Åó„Å¶„Ç™„Éó„Ç∑„Éß„É≥A„Åß„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åó„Å¶„Åè„Å†„Åï„ÅÑ\")\n        return False\n\n# Roboflow„Åã„Çâ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ\ndownload_success = download_roboflow_dataset()"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "manual-setup-header"
   },
   "source": "### „Ç™„Éó„Ç∑„Éß„É≥C: ÊâãÂãï„Éá„Éº„Çø„Çª„ÉÉ„Éà„Çª„ÉÉ„Éà„Ç¢„ÉÉ„ÉóÔºà„ÉÜ„Çπ„ÉàÁî®Ôºâ",
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "manual-dataset"
   },
   "outputs": [],
   "source": "# „Ç™„Éó„Ç∑„Éß„É≥C: „ÉÜ„Çπ„ÉàÁî®„Çµ„É≥„Éó„É´„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆ‰ΩúÊàê\ndef create_sample_dataset():\n    \"\"\"„ÉÜ„Çπ„ÉàÁî®„ÅÆ„Çµ„É≥„Éó„É´„Éá„Éº„Çø„Çª„ÉÉ„ÉàÊßãÈÄ†„Çí‰ΩúÊàê„Åô„Çã\"\"\"\n    print(\"üß™ „ÉÜ„Çπ„ÉàÁî®„ÅÆ„Çµ„É≥„Éó„É´„Éá„Éº„Çø„Çª„ÉÉ„ÉàÊßãÈÄ†„Çí‰ΩúÊàê‰∏≠...\")\n    \n    # „Éá„Ç£„É¨„ÇØ„Éà„É™ÊßãÈÄ†„ÅÆ‰ΩúÊàê\n    base_dir = Path('datasets')\n    for split in ['train', 'valid', 'test']:\n        (base_dir / split / 'images').mkdir(parents=True, exist_ok=True)\n        (base_dir / split / 'labels').mkdir(parents=True, exist_ok=True)\n    \n    # „Çµ„É≥„Éó„É´data.yaml„ÅÆ‰ΩúÊàê\n    data_yaml = {\n        'train': './train/images',\n        'val': './valid/images', \n        'test': './test/images',\n        'nc': 1,\n        'names': ['beetle'],\n        'roboflow': {\n            'workspace': 'z-algae-bilby',\n            'project': 'beetle',\n            'version': 1,\n            'license': 'CC BY 4.0',\n            'url': 'https://universe.roboflow.com/z-algae-bilby/beetle/dataset/1'\n        }\n    }\n    \n    with open(base_dir / 'data.yaml', 'w') as f:\n        yaml.dump(data_yaml, f, default_flow_style=False)\n    \n    print(\"‚úÖ „Çµ„É≥„Éó„É´„Éá„Éº„Çø„Çª„ÉÉ„ÉàÊßãÈÄ†„Çí‰ΩúÊàê„Åó„Åæ„Åó„ÅüÔºÅ\")\n    print(\"‚ö†Ô∏è Ê≥®ÊÑè: „Åì„Çå„ÅØÊßãÈÄ†„ÅÆ„Åø„Åß„Åô„ÄÇÂÆüÈöõ„ÅÆÁîªÂÉè„Å®„É©„Éô„É´„ÇíËøΩÂä†„Åô„ÇãÂøÖË¶Å„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ\")\n    return True\n\n# „Çµ„É≥„Éó„É´ÊßãÈÄ†„Çí‰ΩúÊàê„Åô„Çã„Å´„ÅØ‰ª•‰∏ã„ÅÆË°å„ÅÆ„Ç≥„É°„É≥„Éà„ÇíÂ§ñ„Åó„Å¶„Åè„Å†„Åï„ÅÑ\n# create_sample_dataset()"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "validation-header"
   },
   "source": "## ‚úÖ „Çπ„ÉÜ„ÉÉ„Éó5: „Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆÊ§úË®º„Å®Ëß£Êûê",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "validate-dataset"
   },
   "outputs": [],
   "source": [
    "# Validate dataset structure and contents\n",
    "def validate_dataset(dataset_path='datasets'):\n",
    "    print(\"üîç Validating dataset structure...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    dataset_dir = Path(dataset_path)\n",
    "    \n",
    "    # Check if data.yaml exists\n",
    "    data_yaml_path = dataset_dir / 'data.yaml'\n",
    "    if not data_yaml_path.exists():\n",
    "        print(\"‚ùå data.yaml not found!\")\n",
    "        return False\n",
    "    \n",
    "    # Load and display data.yaml\n",
    "    with open(data_yaml_path, 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "    \n",
    "    print(\"üìÑ Dataset Configuration (data.yaml):\")\n",
    "    for key, value in data_config.items():\n",
    "        if key != 'roboflow':\n",
    "            print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Check directory structure and count files\n",
    "    results = {}\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        images_dir = dataset_dir / split / 'images'\n",
    "        labels_dir = dataset_dir / split / 'labels'\n",
    "        \n",
    "        if images_dir.exists() and labels_dir.exists():\n",
    "            image_files = list(images_dir.glob('*.[jp][pn]g')) + list(images_dir.glob('*.jpeg'))\n",
    "            label_files = list(labels_dir.glob('*.txt'))\n",
    "            \n",
    "            results[split] = {\n",
    "                'images': len(image_files),\n",
    "                'labels': len(label_files)\n",
    "            }\n",
    "            \n",
    "            status = \"‚úÖ\" if len(image_files) == len(label_files) and len(image_files) > 0 else \"‚ö†Ô∏è\"\n",
    "            print(f\"{status} {split.upper()}: {len(image_files)} images, {len(label_files)} labels\")\n",
    "        else:\n",
    "            print(f\"‚ùå {split.upper()}: Directory not found\")\n",
    "            results[split] = {'images': 0, 'labels': 0}\n",
    "    \n",
    "    # Calculate total\n",
    "    total_images = sum(split['images'] for split in results.values())\n",
    "    total_labels = sum(split['labels'] for split in results.values())\n",
    "    \n",
    "    print(f\"\\nüìä TOTAL: {total_images} images, {total_labels} labels\")\n",
    "    \n",
    "    if total_images > 0 and total_images == total_labels:\n",
    "        print(\"‚úÖ Dataset validation successful!\")\n",
    "        return True, data_config, results\n",
    "    else:\n",
    "        print(\"‚ùå Dataset validation failed!\")\n",
    "        return False, None, None\n",
    "\n",
    "# Run validation\n",
    "validation_success, dataset_config, dataset_stats = validate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize-dataset"
   },
   "outputs": [],
   "source": [
    "# Visualize dataset statistics\n",
    "def visualize_dataset_stats(stats):\n",
    "    if not stats:\n",
    "        print(\"‚ùå No dataset statistics to display\")\n",
    "        return\n",
    "    \n",
    "    print(\"üìä Dataset Statistics Visualization\")\n",
    "    \n",
    "    # Create bar plot\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Plot 1: Images per split\n",
    "    splits = list(stats.keys())\n",
    "    image_counts = [stats[split]['images'] for split in splits]\n",
    "    \n",
    "    bars1 = ax1.bar(splits, image_counts, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "    ax1.set_title('Images per Split', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel('Number of Images')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, count in zip(bars1, image_counts):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                str(count), ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Plot 2: Split distribution pie chart\n",
    "    total = sum(image_counts)\n",
    "    percentages = [count/total*100 for count in image_counts]\n",
    "    \n",
    "    ax2.pie(percentages, labels=[f'{split}\\n({count} images)' for split, count in zip(splits, image_counts)], \n",
    "            autopct='%1.1f%%', startangle=90, colors=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "    ax2.set_title('Dataset Split Distribution', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nüìà Dataset Summary:\")\n",
    "    print(f\"Total Images: {total}\")\n",
    "    for split, count in zip(splits, image_counts):\n",
    "        percentage = count/total*100\n",
    "        print(f\"{split.upper()}: {count} images ({percentage:.1f}%)\")\n",
    "\n",
    "# Visualize if validation was successful\n",
    "if validation_success:\n",
    "    visualize_dataset_stats(dataset_stats)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Cannot visualize dataset - validation failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sample-images"
   },
   "outputs": [],
   "source": [
    "# Display sample images from dataset\n",
    "def display_sample_images(dataset_path='datasets', num_samples=6):\n",
    "    if not validation_success:\n",
    "        print(\"‚ö†Ô∏è Cannot display samples - dataset validation failed\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üñºÔ∏è Displaying {num_samples} sample images from training set\")\n",
    "    \n",
    "    dataset_dir = Path(dataset_path)\n",
    "    train_images = list((dataset_dir / 'train' / 'images').glob('*.[jp][pn]g'))\n",
    "    \n",
    "    if len(train_images) == 0:\n",
    "        print(\"‚ùå No images found in training set\")\n",
    "        return\n",
    "    \n",
    "    # Select random samples\n",
    "    sample_images = np.random.choice(train_images, min(num_samples, len(train_images)), replace=False)\n",
    "    \n",
    "    # Create subplot\n",
    "    cols = 3\n",
    "    rows = (num_samples + cols - 1) // cols\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 5*rows))\n",
    "    \n",
    "    if rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i, img_path in enumerate(sample_images):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        \n",
    "        # Load and display image\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        axes[row, col].imshow(img_rgb)\n",
    "        axes[row, col].set_title(f\"Sample {i+1}: {img_path.name}\", fontsize=10)\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for i in range(len(sample_images), rows * cols):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display sample images\n",
    "display_sample_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training-header"
   },
   "source": "## üéØ „Çπ„ÉÜ„ÉÉ„Éó6: „Éà„É¨„Éº„Éã„É≥„Ç∞Ë®≠ÂÆö„Å®„É¢„Éá„É´ÈÅ∏Êäû",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training-config"
   },
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "class TrainingConfig:\n",
    "    \"\"\"Training configuration class\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Model configuration\n",
    "        self.model_size = 'n'  # n, s, m, l, x (nano, small, medium, large, extra-large)\n",
    "        self.pretrained_model = f'yolov8{self.model_size}.pt'\n",
    "        \n",
    "        # Training parameters\n",
    "        self.epochs = 100\n",
    "        self.batch_size = 16  # Adjust based on GPU memory\n",
    "        self.image_size = 640\n",
    "        self.device = 'auto'  # auto, cpu, 0, 1, etc.\n",
    "        \n",
    "        # Data configuration\n",
    "        self.data_yaml = 'datasets/data.yaml'\n",
    "        \n",
    "        # Output configuration\n",
    "        self.project_name = 'training_results'\n",
    "        self.experiment_name = 'beetle_detection_colab'\n",
    "        \n",
    "        # Advanced settings\n",
    "        self.patience = 50  # Early stopping patience\n",
    "        self.save_period = 10  # Save checkpoint every N epochs\n",
    "        self.workers = 2  # Number of dataloader workers\n",
    "        \n",
    "        # Optimization\n",
    "        self.optimizer = 'AdamW'  # SGD, Adam, AdamW\n",
    "        self.lr0 = 0.01  # Initial learning rate\n",
    "        self.weight_decay = 0.0005\n",
    "        \n",
    "    def display_config(self):\n",
    "        \"\"\"Display current configuration\"\"\"\n",
    "        print(\"üéØ Training Configuration\")\n",
    "        print(\"=\"*40)\n",
    "        print(f\"Model: {self.pretrained_model}\")\n",
    "        print(f\"Epochs: {self.epochs}\")\n",
    "        print(f\"Batch Size: {self.batch_size}\")\n",
    "        print(f\"Image Size: {self.image_size}\")\n",
    "        print(f\"Device: {self.device}\")\n",
    "        print(f\"Dataset: {self.data_yaml}\")\n",
    "        print(f\"Project: {self.project_name}/{self.experiment_name}\")\n",
    "        print(f\"Optimizer: {self.optimizer}\")\n",
    "        print(f\"Learning Rate: {self.lr0}\")\n",
    "        print(f\"Weight Decay: {self.weight_decay}\")\n",
    "        print(\"=\"*40)\n",
    "\n",
    "# Create configuration\n",
    "config = TrainingConfig()\n",
    "config.display_config()\n",
    "\n",
    "# GPU memory optimization\n",
    "if torch.cuda.is_available():\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"\\nüéÆ GPU Memory: {gpu_memory:.1f} GB\")\n",
    "    \n",
    "    # Adjust batch size based on GPU memory\n",
    "    if gpu_memory < 8:\n",
    "        config.batch_size = 8\n",
    "        print(\"‚ö° Reduced batch size to 8 for GPU memory optimization\")\n",
    "    elif gpu_memory >= 16:\n",
    "        config.batch_size = 32\n",
    "        print(\"üöÄ Increased batch size to 32 for better GPU utilization\")\n",
    "    \n",
    "print(f\"\\nüìä Final Batch Size: {config.batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model-training-header"
   },
   "source": "## üöÄ „Çπ„ÉÜ„ÉÉ„Éó7: „É¢„Éá„É´„Éà„É¨„Éº„Éã„É≥„Ç∞ÂÆüË°å",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load-model"
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "def load_pretrained_model(model_name):\n",
    "    print(f\"üì• Loading pre-trained model: {model_name}\")\n",
    "    \n",
    "    try:\n",
    "        model = YOLO(model_name)\n",
    "        print(f\"‚úÖ Model loaded successfully!\")\n",
    "        \n",
    "        # Display model info\n",
    "        print(f\"\\nüìã Model Information:\")\n",
    "        print(f\"Model file: {model_name}\")\n",
    "        print(f\"Task: {model.task}\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading model: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load the model\n",
    "model = load_pretrained_model(config.pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training-execution"
   },
   "outputs": [],
   "source": [
    "# Execute model training\n",
    "def train_model(model, config):\n",
    "    if model is None:\n",
    "        print(\"‚ùå Cannot start training - model not loaded\")\n",
    "        return None\n",
    "    \n",
    "    if not validation_success:\n",
    "        print(\"‚ùå Cannot start training - dataset validation failed\")\n",
    "        return None\n",
    "    \n",
    "    print(\"üöÄ Starting model training...\")\n",
    "    print(\"‚è±Ô∏è This may take a while depending on your configuration\")\n",
    "    print(\"üìä Training progress will be displayed below\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Record start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Start training\n",
    "        results = model.train(\n",
    "            data=config.data_yaml,\n",
    "            epochs=config.epochs,\n",
    "            batch=config.batch_size,\n",
    "            imgsz=config.image_size,\n",
    "            device=config.device,\n",
    "            project=config.project_name,\n",
    "            name=config.experiment_name,\n",
    "            save=True,\n",
    "            save_period=config.save_period,\n",
    "            patience=config.patience,\n",
    "            workers=config.workers,\n",
    "            optimizer=config.optimizer,\n",
    "            lr0=config.lr0,\n",
    "            weight_decay=config.weight_decay,\n",
    "            val=True,\n",
    "            plots=True,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # Calculate training time\n",
    "        training_time = time.time() - start_time\n",
    "        hours = int(training_time // 3600)\n",
    "        minutes = int((training_time % 3600) // 60)\n",
    "        seconds = int(training_time % 60)\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        print(f\"‚úÖ Training completed successfully!\")\n",
    "        print(f\"‚è±Ô∏è Total training time: {hours:02d}:{minutes:02d}:{seconds:02d}\")\n",
    "        print(f\"üìÅ Results saved to: {config.project_name}/{config.experiment_name}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Training failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Start training (this will take a while!)\n",
    "print(\"‚ö†Ô∏è Warning: Training will start in 5 seconds...\")\n",
    "time.sleep(5)\n",
    "\n",
    "training_results = train_model(model, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results-header"
   },
   "source": "## üìä „Çπ„ÉÜ„ÉÉ„Éó8: „Éà„É¨„Éº„Éã„É≥„Ç∞ÁµêÊûú„ÅÆËß£Êûê„Å®ÂèØË¶ñÂåñ",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "display-results"
   },
   "outputs": [],
   "source": [
    "# Display training results\n",
    "def display_training_results(results, config):\n",
    "    if results is None:\n",
    "        print(\"‚ùå No training results to display\")\n",
    "        return\n",
    "    \n",
    "    print(\"üìä Training Results Summary\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Results directory\n",
    "    results_dir = Path(config.project_name) / config.experiment_name\n",
    "    \n",
    "    # Display key metrics if available\n",
    "    if hasattr(results, 'results_dict'):\n",
    "        metrics = results.results_dict\n",
    "        print(\"üéØ Final Metrics:\")\n",
    "        for key, value in metrics.items():\n",
    "            if isinstance(value, (int, float)):\n",
    "                print(f\"  {key}: {value:.4f}\")\n",
    "    \n",
    "    # Check for results plots\n",
    "    plots_to_show = [\n",
    "        ('results.png', 'üìà Training/Validation Curves'),\n",
    "        ('confusion_matrix.png', 'üéØ Confusion Matrix'),\n",
    "        ('labels.jpg', 'üìä Label Distribution'),\n",
    "        ('val_batch0_pred.jpg', 'üîç Validation Predictions')\n",
    "    ]\n",
    "    \n",
    "    for plot_file, title in plots_to_show:\n",
    "        plot_path = results_dir / plot_file\n",
    "        if plot_path.exists():\n",
    "            print(f\"\\n{title}\")\n",
    "            display(Image(str(plot_path)))\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è {title} not found: {plot_path}\")\n",
    "\n",
    "# Display results\n",
    "if training_results:\n",
    "    display_training_results(training_results, config)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No training results available to display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model-validation"
   },
   "outputs": [],
   "source": [
    "# Load best model and run validation\n",
    "def validate_trained_model(config):\n",
    "    print(\"üß™ Loading best model for validation...\")\n",
    "    \n",
    "    # Path to best model\n",
    "    best_model_path = Path(config.project_name) / config.experiment_name / 'weights' / 'best.pt'\n",
    "    \n",
    "    if not best_model_path.exists():\n",
    "        print(f\"‚ùå Best model not found: {best_model_path}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Load best model\n",
    "        best_model = YOLO(str(best_model_path))\n",
    "        print(f\"‚úÖ Best model loaded from: {best_model_path}\")\n",
    "        \n",
    "        # Run validation\n",
    "        print(\"\\nüéØ Running validation on test set...\")\n",
    "        val_results = best_model.val(data=config.data_yaml)\n",
    "        \n",
    "        # Display validation metrics\n",
    "        if hasattr(val_results, 'box'):\n",
    "            box_metrics = val_results.box\n",
    "            print(\"\\nüìä Validation Metrics:\")\n",
    "            print(f\"  mAP@0.5: {box_metrics.map50:.4f}\")\n",
    "            print(f\"  mAP@0.5:0.95: {box_metrics.map:.4f}\")\n",
    "            print(f\"  Precision: {box_metrics.mp:.4f}\")\n",
    "            print(f\"  Recall: {box_metrics.mr:.4f}\")\n",
    "        \n",
    "        return best_model, val_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Validation failed: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Run validation if training was successful\n",
    "if training_results:\n",
    "    best_model, validation_results = validate_trained_model(config)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skipping validation - training was not completed\")\n",
    "    best_model, validation_results = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inference-header"
   },
   "source": "## üîç „Çπ„ÉÜ„ÉÉ„Éó9: „É¢„Éá„É´Êé®Ë´ñ„Å®„ÉÜ„Çπ„Éà",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test-inference"
   },
   "outputs": [],
   "source": [
    "# Test model inference on sample images\n",
    "def test_model_inference(model, config, num_samples=4):\n",
    "    if model is None:\n",
    "        print(\"‚ùå No model available for testing\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üîç Testing model inference on {num_samples} sample images...\")\n",
    "    \n",
    "    # Get test images\n",
    "    test_images_dir = Path('datasets/test/images')\n",
    "    if not test_images_dir.exists():\n",
    "        # Fallback to validation images\n",
    "        test_images_dir = Path('datasets/valid/images')\n",
    "    \n",
    "    if not test_images_dir.exists():\n",
    "        print(\"‚ùå No test images found\")\n",
    "        return\n",
    "    \n",
    "    # Get sample images\n",
    "    image_files = list(test_images_dir.glob('*.[jp][pn]g'))\n",
    "    if len(image_files) == 0:\n",
    "        print(\"‚ùå No image files found\")\n",
    "        return\n",
    "    \n",
    "    sample_images = np.random.choice(image_files, min(num_samples, len(image_files)), replace=False)\n",
    "    \n",
    "    # Create subplot for results\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, img_path in enumerate(sample_images):\n",
    "        if i >= len(axes):\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            # Run inference\n",
    "            results = model(str(img_path))\n",
    "            \n",
    "            # Get annotated image\n",
    "            annotated_img = results[0].plot()\n",
    "            \n",
    "            # Convert BGR to RGB for matplotlib\n",
    "            annotated_img_rgb = cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Display image\n",
    "            axes[i].imshow(annotated_img_rgb)\n",
    "            \n",
    "            # Get detection info\n",
    "            detections = len(results[0].boxes) if results[0].boxes is not None else 0\n",
    "            confidence = results[0].boxes.conf.max().item() if detections > 0 else 0\n",
    "            \n",
    "            axes[i].set_title(f\"{img_path.name}\\nDetections: {detections}, Max Conf: {confidence:.3f}\", \n",
    "                            fontsize=10)\n",
    "            axes[i].axis('off')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {img_path.name}: {e}\")\n",
    "            axes[i].text(0.5, 0.5, f\"Error: {str(e)[:50]}...\", \n",
    "                        ha='center', va='center', transform=axes[i].transAxes)\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(len(sample_images), len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('üîç Model Inference Results', fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "# Test inference\n",
    "if best_model:\n",
    "    test_model_inference(best_model, config)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skipping inference test - no trained model available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "export-header"
   },
   "source": "## üíæ „Çπ„ÉÜ„ÉÉ„Éó10: „É¢„Éá„É´„Ç®„ÇØ„Çπ„Éù„Éº„Éà„Å®„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export-model"
   },
   "outputs": [],
   "source": [
    "# Export model to different formats\n",
    "def export_trained_model(model, config, formats=['onnx', 'torchscript']):\n",
    "    if model is None:\n",
    "        print(\"‚ùå No model available for export\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üì¶ Exporting model to formats: {formats}\")\n",
    "    \n",
    "    exported_files = []\n",
    "    \n",
    "    for format_type in formats:\n",
    "        try:\n",
    "            print(f\"\\nüîÑ Exporting to {format_type.upper()}...\")\n",
    "            export_path = model.export(format=format_type, imgsz=config.image_size)\n",
    "            exported_files.append(export_path)\n",
    "            print(f\"‚úÖ {format_type.upper()} export successful: {export_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå {format_type.upper()} export failed: {e}\")\n",
    "    \n",
    "    if exported_files:\n",
    "        print(f\"\\nüéâ Successfully exported {len(exported_files)} model formats\")\n",
    "        for file_path in exported_files:\n",
    "            print(f\"  üìÑ {file_path}\")\n",
    "    \n",
    "    return exported_files\n",
    "\n",
    "# Export model\n",
    "if best_model:\n",
    "    exported_models = export_trained_model(best_model, config)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skipping model export - no trained model available\")\n",
    "    exported_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copy-to-drive"
   },
   "outputs": [],
   "source": [
    "# Copy results to Google Drive\n",
    "def copy_results_to_drive(config):\n",
    "    print(\"üíæ Copying training results to Google Drive...\")\n",
    "    \n",
    "    # Source directory\n",
    "    source_dir = Path(config.project_name) / config.experiment_name\n",
    "    \n",
    "    # Destination directory in Google Drive\n",
    "    drive_dir = Path('/content/drive/MyDrive/insect_detection_training/results') / config.experiment_name\n",
    "    \n",
    "    if not source_dir.exists():\n",
    "        print(f\"‚ùå Source directory not found: {source_dir}\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Create destination directory\n",
    "        drive_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Copy entire results directory\n",
    "        import shutil\n",
    "        shutil.copytree(source_dir, drive_dir, dirs_exist_ok=True)\n",
    "        \n",
    "        print(f\"‚úÖ Results copied to: {drive_dir}\")\n",
    "        \n",
    "        # List important files\n",
    "        important_files = [\n",
    "            'weights/best.pt',\n",
    "            'weights/last.pt', \n",
    "            'results.png',\n",
    "            'confusion_matrix.png'\n",
    "        ]\n",
    "        \n",
    "        print(\"\\nüìÅ Important files in Google Drive:\")\n",
    "        for file_path in important_files:\n",
    "            full_path = drive_dir / file_path\n",
    "            if full_path.exists():\n",
    "                size_mb = full_path.stat().st_size / (1024 * 1024)\n",
    "                print(f\"  ‚úÖ {file_path} ({size_mb:.1f} MB)\")\n",
    "            else:\n",
    "                print(f\"  ‚ùå {file_path} (not found)\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error copying to Google Drive: {e}\")\n",
    "        return False\n",
    "\n",
    "# Copy results to Google Drive\n",
    "if training_results:\n",
    "    copy_success = copy_results_to_drive(config)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skipping copy to Google Drive - no training results available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-models"
   },
   "outputs": [],
   "source": [
    "# Download trained models to local computer\n",
    "def download_models(config):\n",
    "    print(\"‚¨áÔ∏è Preparing model files for download...\")\n",
    "    \n",
    "    results_dir = Path(config.project_name) / config.experiment_name\n",
    "    weights_dir = results_dir / 'weights'\n",
    "    \n",
    "    if not weights_dir.exists():\n",
    "        print(f\"‚ùå Weights directory not found: {weights_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Files to download\n",
    "    download_files = {\n",
    "        'best.pt': 'Best model weights',\n",
    "        'last.pt': 'Last epoch weights'\n",
    "    }\n",
    "    \n",
    "    print(\"\\nüì• Available for download:\")\n",
    "    \n",
    "    for filename, description in download_files.items():\n",
    "        file_path = weights_dir / filename\n",
    "        if file_path.exists():\n",
    "            size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "            print(f\"  üìÑ {filename}: {description} ({size_mb:.1f} MB)\")\n",
    "            \n",
    "            # Trigger download\n",
    "            try:\n",
    "                files.download(str(file_path))\n",
    "                print(f\"  ‚úÖ {filename} download initiated\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ùå Error downloading {filename}: {e}\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå {filename}: Not found\")\n",
    "    \n",
    "    # Also download results plot\n",
    "    results_plot = results_dir / 'results.png'\n",
    "    if results_plot.exists():\n",
    "        try:\n",
    "            files.download(str(results_plot))\n",
    "            print(f\"  ‚úÖ results.png download initiated\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error downloading results.png: {e}\")\n",
    "\n",
    "# Download models\n",
    "if training_results:\n",
    "    download_models(config)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No models available for download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary-header"
   },
   "source": "## üìã „Çπ„ÉÜ„ÉÉ„Éó11: „Éà„É¨„Éº„Éã„É≥„Ç∞„Çµ„Éû„É™„Éº„Å®Ê¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training-summary"
   },
   "outputs": [],
   "source": [
    "# Generate training summary\n",
    "def generate_training_summary(config, training_results, validation_results):\n",
    "    print(\"üìã TRAINING SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Basic information\n",
    "    print(f\"üéØ Project: {config.project_name}/{config.experiment_name}\")\n",
    "    print(f\"ü§ñ Model: {config.pretrained_model}\")\n",
    "    print(f\"üìä Dataset: {config.data_yaml}\")\n",
    "    print(f\"‚öôÔ∏è Configuration:\")\n",
    "    print(f\"   - Epochs: {config.epochs}\")\n",
    "    print(f\"   - Batch Size: {config.batch_size}\")\n",
    "    print(f\"   - Image Size: {config.image_size}\")\n",
    "    print(f\"   - Device: {config.device}\")\n",
    "    \n",
    "    # Training status\n",
    "    if training_results:\n",
    "        print(f\"\\n‚úÖ Training Status: COMPLETED\")\n",
    "        \n",
    "        # Validation metrics\n",
    "        if validation_results and hasattr(validation_results, 'box'):\n",
    "            box_metrics = validation_results.box\n",
    "            print(f\"\\nüìä Final Metrics:\")\n",
    "            print(f\"   - mAP@0.5: {box_metrics.map50:.4f}\")\n",
    "            print(f\"   - mAP@0.5:0.95: {box_metrics.map:.4f}\")\n",
    "            print(f\"   - Precision: {box_metrics.mp:.4f}\")\n",
    "            print(f\"   - Recall: {box_metrics.mr:.4f}\")\n",
    "            \n",
    "            # Performance evaluation\n",
    "            if box_metrics.map50 >= 0.7:\n",
    "                print(f\"   üéâ EXCELLENT: Model meets target performance (mAP@0.5 ‚â• 0.7)\")\n",
    "            elif box_metrics.map50 >= 0.5:\n",
    "                print(f\"   ‚úÖ GOOD: Model shows good performance (mAP@0.5 ‚â• 0.5)\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è FAIR: Model needs improvement (mAP@0.5 < 0.5)\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Training Status: FAILED or INCOMPLETE\")\n",
    "    \n",
    "    # File locations\n",
    "    results_dir = Path(config.project_name) / config.experiment_name\n",
    "    drive_dir = Path('/content/drive/MyDrive/insect_detection_training/results') / config.experiment_name\n",
    "    \n",
    "    print(f\"\\nüìÅ Output Locations:\")\n",
    "    print(f\"   - Local: {results_dir}\")\n",
    "    print(f\"   - Google Drive: {drive_dir}\")\n",
    "    \n",
    "    # Next steps\n",
    "    print(f\"\\nüöÄ Next Steps:\")\n",
    "    print(f\"   1. Download model files (best.pt) for deployment\")\n",
    "    print(f\"   2. Test model on new images\")\n",
    "    print(f\"   3. Deploy to production environment\")\n",
    "    print(f\"   4. Monitor performance on real data\")\n",
    "    \n",
    "    if training_results:\n",
    "        print(f\"\\nüí° Optimization Tips:\")\n",
    "        if validation_results and hasattr(validation_results, 'box'):\n",
    "            if validation_results.box.map50 < 0.7:\n",
    "                print(f\"   - Try training for more epochs\")\n",
    "                print(f\"   - Increase model size (yolov8s or yolov8m)\")\n",
    "                print(f\"   - Add more training data\")\n",
    "                print(f\"   - Adjust data augmentation\")\n",
    "            else:\n",
    "                print(f\"   - Model performance is good!\")\n",
    "                print(f\"   - Consider model compression for deployment\")\n",
    "                print(f\"   - Test on edge devices (Raspberry Pi)\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Generate summary\n",
    "generate_training_summary(config, training_results, validation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "usage-examples"
   },
   "outputs": [],
   "source": [
    "# Usage examples for trained model\n",
    "def show_usage_examples(config):\n",
    "    print(\"üíª USAGE EXAMPLES\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    model_path = f\"{config.project_name}/{config.experiment_name}/weights/best.pt\"\n",
    "    \n",
    "    print(\"\\nüêç Python Usage:\")\n",
    "    print(\"```python\")\n",
    "    print(\"from ultralytics import YOLO\")\n",
    "    print(\"\")\n",
    "    print(f\"# Load trained model\")\n",
    "    print(f\"model = YOLO('{model_path}')\")\n",
    "    print(\"\")\n",
    "    print(\"# Run inference on single image\")\n",
    "    print(\"results = model('path/to/image.jpg')\")\n",
    "    print(\"\")\n",
    "    print(\"# Run inference on multiple images\")\n",
    "    print(\"results = model(['img1.jpg', 'img2.jpg'])\")\n",
    "    print(\"\")\n",
    "    print(\"# Save results with annotations\")\n",
    "    print(\"for r in results:\")\n",
    "    print(\"    r.save(filename='result.jpg')\")\n",
    "    print(\"```\")\n",
    "    \n",
    "    print(\"\\nüñ•Ô∏è Command Line Usage:\")\n",
    "    print(\"```bash\")\n",
    "    print(f\"# Single image prediction\")\n",
    "    print(f\"yolo predict model={model_path} source=image.jpg\")\n",
    "    print(\"\")\n",
    "    print(f\"# Batch prediction\")\n",
    "    print(f\"yolo predict model={model_path} source=images_folder/\")\n",
    "    print(\"\")\n",
    "    print(f\"# Video prediction\")\n",
    "    print(f\"yolo predict model={model_path} source=video.mp4\")\n",
    "    print(\"```\")\n",
    "    \n",
    "    print(\"\\nüåê Integration with detect_insect.py:\")\n",
    "    print(\"```bash\")\n",
    "    print(f\"# Use trained model with detection script\")\n",
    "    print(f\"python detect_insect.py \\\\\")\n",
    "    print(f\"    --input input_images/ \\\\\")\n",
    "    print(f\"    --output output_images/ \\\\\")\n",
    "    print(f\"    --model {model_path}\")\n",
    "    print(\"```\")\n",
    "    \n",
    "    print(\"\\nüì± Export for Edge Deployment:\")\n",
    "    print(\"```python\")\n",
    "    print(\"# Export to ONNX for cross-platform deployment\")\n",
    "    print(f\"model = YOLO('{model_path}')\")\n",
    "    print(\"model.export(format='onnx')\")\n",
    "    print(\"\")\n",
    "    print(\"# Export to TensorRT for NVIDIA GPUs\")\n",
    "    print(\"model.export(format='engine')\")\n",
    "    print(\"```\")\n",
    "\n",
    "# Show usage examples\n",
    "if training_results:\n",
    "    show_usage_examples(config)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No usage examples available - training was not completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "footer"
   },
   "source": "---\n\n## üéâ „Éà„É¨„Éº„Éã„É≥„Ç∞ÂÆå‰∫ÜÔºÅ\n\n**„Åä„ÇÅ„Åß„Å®„ÅÜ„Åî„Åñ„ÅÑ„Åæ„ÅôÔºÅ** ÊòÜËô´Ê§úÂá∫„ÅÆ„Åü„ÇÅ„ÅÆYOLOv8„Éà„É¨„Éº„Éã„É≥„Ç∞„Éë„Ç§„Éó„É©„Ç§„É≥„ÅåÊ≠£Â∏∏„Å´ÂÆå‰∫Ü„Åó„Åæ„Åó„Åü„ÄÇ\n\n### üìã ÈÅîÊàê„Åó„ÅüÂÜÖÂÆπ:\n- ‚úÖ GPUÂä†ÈÄü„Éà„É¨„Éº„Éã„É≥„Ç∞Áí∞Â¢É„ÅÆ„Çª„ÉÉ„Éà„Ç¢„ÉÉ„Éó\n- ‚úÖ „Ç´„Éñ„Éà„É†„Ç∑Ê§úÂá∫„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅÆÊ∫ñÂÇô„Å®Ê§úË®º\n- ‚úÖ „Ç´„Çπ„Çø„É†YOLOv8„É¢„Éá„É´„ÅÆË®ìÁ∑¥\n- ‚úÖ „É¢„Éá„É´ÊÄßËÉΩ„ÅÆË©ï‰æ°\n- ‚úÖ Â±ïÈñãÁî®„É¢„Éá„É´„ÅÆ„Ç®„ÇØ„Çπ„Éù„Éº„Éà\n- ‚úÖ ÁµêÊûú„ÅÆGoogle Drive„Å∏„ÅÆ‰øùÂ≠ò\n\n### üöÄ Ê¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó:\n1. **Ë®ìÁ∑¥Ê∏à„Åø„É¢„Éá„É´„ÅÆ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ** (`best.pt`) „Çí„É≠„Éº„Ç´„É´„Åß‰ΩøÁî®\n2. **Êñ∞„Åó„ÅÑ„Ç´„Éñ„Éà„É†„Ç∑ÁîªÂÉè„Åß„ÅÆ„ÉÜ„Çπ„Éà**\n3. **Êèê‰æõ„Åï„Çå„Åü‰ΩøÁî®‰æã„Çí‰ΩøÁî®„Åó„ÅüÊú¨Áï™Áí∞Â¢É„Å∏„ÅÆÂ±ïÈñã**\n4. **ÊÄßËÉΩ„ÅÆÁõ£Ë¶ñ** „Å®ÂøÖË¶Å„Å´Âøú„Åò„ÅüÂÜçË®ìÁ∑¥\n\n### üìö „É™„ÇΩ„Éº„Çπ:\n- [YOLOv8 „Éâ„Ç≠„É•„É°„É≥„Éà](https://docs.ultralytics.com/)\n- [„É¢„Éá„É´Â±ïÈñã„Ç¨„Ç§„Éâ](https://docs.ultralytics.com/modes/export/)\n- [ÊÄßËÉΩÊúÄÈÅ©Âåñ](https://docs.ultralytics.com/guides/model-optimization/)\n\n---\n\n*üêõ Ê•Ω„Åó„ÅÑ„Ç´„Éñ„Éà„É†„Ç∑Ê§úÂá∫„ÇíÔºÅ üêõ*",
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}